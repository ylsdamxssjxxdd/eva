# 01 对话：日常聊天

[返回总览](GitHubPages用户引导.md) · [下一页：补完](02-补完.md)

## 🎯 适用场景

- **初次体验**：第一次使用 EVA，想快速与模型对话，感受智能体能力。
- **日常助手**：问答、代码解释、方案讨论、翻译、总结等文本任务。
- **多模态交互**：需要模型基于图片、音频内容给出反馈（例如分析截图、解读图表、转写语音）。
- **工具调用预热**：在启用复杂工具前，先通过简单对话验证模型与后端连通性。

## 📦 你会得到

- **完整对话流程**：从装载模型到发送消息、接收流式回复的全过程体验。
- **界面熟悉**：了解五个核心按钮的功能、状态提示含义、常用快捷键。
- **多模态支持**：掌握如何附加图片、音频，让模型“看见”和“听见”。
- **性能观测**：学会查看生成速度、上下文占用等实时指标。

## ⚙️ 前置准备（约 1 分钟）

确保已完成以下任一模式的基础准备：

### 本地模式
1. **后端就绪**：`EVA_BACKEND` 目录中存在与您系统匹配的可执行文件（例如 `EVA_BACKEND/x86_64/win/cuda/llama.cpp/llama-server.exe`）。
2. **模型就绪**：至少一个 GGUF 格式的语言模型文件，可放在 `EVA_MODELS/llm` 目录（EVA 会自动扫描最小模型作为默认）。

### 链接模式
1. **API 信息**：拥有一个 OpenAI 兼容端点的 URL、API 密钥以及可用的模型名称。
2. **网络畅通**：确保可访问该端点，且未被防火墙或代理阻断。

> **提示**：如果您是第一次启动 EVA 且未进行任何配置，应用会自动扫描 `EVA_MODELS` 目录，为各功能选择最小的默认模型并写入配置。

## 🚀 操作步骤（图文对照）

### 步骤 1：装载模型
1. 启动 EVA，点击主界面左上角的 **“装载”** 按钮。
2. 在弹出的选择对话框中：
   - **本地模式**：点击“本地模式”，从文件浏览器中选择一个 GGUF 模型文件（默认会指向 `EVA_MODELS/llm` 中最小的模型）。确认后，界面进入 **“装载中”** 状态（按钮锁定、转轮动画）。
   - **链接模式**：点击“链接模式”，依次填写：
     - **Endpoint**：例如 `https://api.openai.com/v1`
     - **API Key**：您的密钥
     - **Model**：例如 `gpt-4o-mini`
     确认后，EVA 会停止本地服务（若正在运行），切换为远端连接。
3. 等待装载完成。本地模式会启动 llama.cpp server，并在“模型日志”页显示 `listening on 127.0.0.1:8080` 等就绪信息；链接模式会尝试连接远端并验证密钥。成功后界面状态变为 **“正常”**。

### 步骤 2：输入与发送
1. 在底部输入框键入您的消息（支持 Markdown 粗体、列表等格式）。
2. 如需附加内容：
   - **图片**：直接将图片文件拖拽到输入框，或按 `F1` 键截取屏幕区域（截屏后自动附加）。
   - **音频**：点击输入框右侧的上传按钮，选择 WAV/MP3/OGG/FLAC 文件；或按 `F2` 开始录音，再次按 `F2` 结束，录音会自动转写并填入输入框。
3. 按下 `Ctrl+Enter` 或点击 **“发送”** 按钮。界面状态会切换为 **“推理中”**，此时仅 **“重置”** 按钮可用。

### 步骤 3：观察回复
- **流式输出**：模型的回复会逐字出现在输出区域，同时显示实时生成速度（如 `12.5 token/s`）。
- **上下文占用**：顶部进度条展示当前对话已使用的 Token 数占总上下文长度的比例。
- **思考过程**：如果模型启用了 reasoning，您会看到 `</think>...</think>` 格式的思考段落（通常为灰色背景）。
- **工具调用**：若在“约定”中启用了工具，模型可能会输出 `<tool_call>...</tool_call>`，EVA 会自动执行并在对话中插入 `tool_response:`。

### 步骤 4：继续对话
回复结束后，状态恢复为 **“正常”**。您可以直接输入下一条消息，开启多轮对话。所有历史消息会保留在上下文中，直到点击 **“重置”**（第一次点击终止当前推理，第二次点击清空对话并新建会话）。

## 🎮 界面提示与快捷键

### 五个核心按钮
| 按钮 | 功能 | 可用状态 |
|------|------|----------|
| **装载** | 选择本地/链接模式，加载模型与后端。 | 装载前唯一可用；装载中禁用；正常时可用。 |
| **约定** | 编辑系统提示词、昵称，启用/禁用工具。 | 正常时可用；推理中禁用。 |
| **设置** | 调整温度、top_k、top_p 等采样参数，以及后端设备、端口等。 | 正常时可用；推理中禁用。 |
| **重置** | 第一次点击终止当前推理；第二次点击清空对话并新建会话。 | 任何状态均可点击，但在推理中为唯一可用按钮。 |
| **发送** | 将当前输入内容（含图片/音频）发送给模型。 | 正常时可用；装载中、推理中、录音中禁用。 |

### 快捷键一览
- **F1**：截取屏幕（当前活动窗口或自定义区域），截图自动附加到输入框。
- **F2**：录音控制。第一次按选择 Whisper 模型（若未选），第二次按开始录音，第三次按结束并转写。
- **Ctrl+Enter**：发送消息（等同于点击“发送”按钮）。
- **Ctrl+C**（在终端面板）：中断正在执行的命令（仅当系统工程师工具激活时）。

### 状态指示灯
EVA 界面右上角有状态标签，颜色与文字提示当前阶段：
- **装载前**：灰色，仅“装载”按钮可点击。
- **装载中**：橙色，所有按钮禁用，显示转轮动画。
- **正常**：绿色，全部按钮可用，可自由交互。
- **推理中**：蓝色，仅“重置”按钮可用，显示流式输出。
- **录音中**：紫色，F2 控制录音启停，其他按钮部分禁用。

## ❓ 常见问题与排查

### 1. 装载卡住，长时间无响应
- **本地模式**：打开“增殖”窗口的“模型日志”页，检查是否有 `listening on` 或 `ready` 日志。若无，可能是模型路径错误、后端可执行文件权限不足、GPU 显存不足导致启动失败。尝试在“设置”中切换为 CPU 模式，或减少 GPU 层数（ngl）。
- **链接模式**：检查 endpoint 是否可达（用 curl 或浏览器测试），API 密钥是否正确，模型名称是否在端点中可用。注意 endpoint 需包含 `/v1` 路径。

### 2. 发送后无回复，SSE 流未开始
- 确认网络连接正常（本地模式检查 `127.0.0.1:8080` 是否连通）。
- 查看“模型日志”是否有错误信息，例如 `invalid api key` 或 `model not found`。
- 若使用代理，确保代理不会干扰 Server-Sent Events（SSE）流。

### 3. 图片/音频发送后模型未识别
- 图片：确认图片已正确附加（输入框下方会出现缩略图）。本地模式需在“设置”中勾选视觉模型（mmproj）并确保对应 GGUF 文件存在。
- 音频：确认音频格式为支持的 WAV/MP3/OGG/FLAC，大小不超过 20 MB。链接模式需要端点支持 `input_audio` 字段。

### 4. 流式输出速度慢，Token/s 很低
- 本地模式：检查 GPU 利用率（可通过任务管理器），若 CPU 模式则速度自然较慢。可尝试增加 batch size、调整线程数（在“设置”中）。
- 链接模式：受远端服务器负载和网络延迟影响，可尝试更换端点或模型。

### 5. 上下文占用快速增长，导致后续回复截断
- 长对话会积累历史 Token，可在适当时候点击 **“重置”** 清空对话（注意会丢失上下文）。
- 在“设置”中增大 `nctx`（上下文长度）可容纳更多历史，但会提高内存/显存占用。

## 📸 界面截图

![对话页面示意图](../images/pages/01-chat.png)

> **下一步**：掌握基础对话后，可进入 **[补完：初始形态](02-补完.md)** 学习一次性长文续写，或继续探索其他功能。
